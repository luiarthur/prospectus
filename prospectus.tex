% Template
\documentclass[]{statthesisMEMOIR}
 
%\documentclass{article}                                                   %
\usepackage{fullpage}                                                     %
\usepackage{pgffor}                                                       %
\usepackage{amssymb}                                                      %
\usepackage{Sweave}                                                       %
\usepackage{bm}                                                           %
\usepackage{mathtools}                                                    %
\usepackage{verbatim}                                                     %
\usepackage{appendix}                                                     %
\usepackage[UKenglish]{isodate} % for: \today                             %
\cleanlookdateon                % for: \today                             %
                                                                          %
\def\wl{\par \vspace{\baselineskip}\noindent}                             %
\def\beginmyfig{\begin{figure}[htbp]\begin{center}}                       %
\def\endmyfig{\end{center}\end{figure}}                                   %
%\def\prodl{\prod\limits_{i=1}^n}                                         %
%\def\suml{\sum\limits_{i=1}^n}                                           %
\def\prodl#1#2#3{\prod\limits_{#1=#2}^{#3}}                               %
\def\suml#1#2#3{\sum\limits_{#1=#2}^{#3}}                                 %
\def\ds{\displaystyle}                                                    %
\def\piano#1#2#3#4{\frac{\ds #1}{\ds\int_{#2}^{#3}#1 d#4}}                %
\def\mleStart#1#2{\mathcal{L}(#2|\bm{#1}) &=& \prodl f(#1_i|#2)}          %
\def\dig#1#2#3{\frac{1}{\Gamma(#2)#3 ^ #2} (#1)^{-( #2+1)} e^{\frac{-1}{#3 #1}}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Infinite Latent Feature Models Indexed by \titlebreak 
       Pairwise Distance Information}
\author{Arthur Lui}
\chair{David B. Dahl}
\committee{x1}
\committeetwo{x2}
\typeofwork{Project} % project or thesis
\graddate{April 2014}
\copyrightyear{2014}
\keywords{Bayesian nonparametrics, Indian buffet process, latent feature models}
\abstract{test}
\acknowledgments{awesome}

\begin{document}

\section{Introduction} % ~ 1-2 pages. Define the problem.
%The goal of this project is to extend the Indian Buffet Process (IBP) to include
%distance dependency. 

\section{Literature Review} % ~ 15 pages: Do this first.
We will first review the Indian buffet process (IBP). We will then review the 
distance dependent Indian buffet process.

\subsection{The Indian buffet process}
The Indian buffet process is a distribution on infinite sparse (left-ordered)
binary matrices. (i.e. matrices with finite number of rows and infinite number
of columns, ordered by the magnitude of their columns when expressed as a
binary number.) The IBP is a multivariate extension of the Chinese restaurant
process. For an N x K matrix, Z, that follows an IBP($\alpha$) distribution,
element $z_{ik}$ is 1 if observation (customer) i possess feature (dish) k, and
0 otherwise.  And $\alpha$ is a parameter that determines the sparsity of the
matrix. The larger $\alpha$ is, the more likely Z will be sparse. The process
can be generated as follows: \\

\noindent
N customers enter a buffet one after another. The buffet line contains an
infinite number of dishes. The first customer takes the first Poisson($\alpha$)
number of dishes. The $i^{th}$ customer then takes previously sampled dishes
with probability proportional to their popularity, serving himself with
probability $\frac{m_k}{i}$, where $m_k$ is the number of people that had
previously taken dish k. After customer i has sampled all the previously sampled
dishes, he samples Poisson($\frac{\alpha}{i}$) new dishes. The probability of 
any matrix being generated by this process is
\begin{equation}
  P(\bm{Z}) = \frac{\alpha^{K_+}}{\prodl{i}{1}{N} K_1^{(i)}!} 
              exp\{-\alpha H_N\}\prodl{k}{1}{K_+}
              \frac{(N-m_k)!(m_k-1)!}{N!},
\end{equation}
where $H_N$ is the harmonic number, $\suml{i}{1}{N}\ds\frac{1}{i}$, $K_+$ is the 
number of non-zero columns in $\bm Z$, and $K_1^{(i)}$ is the number of new dishes
sampled by customer i.

\subsection{Gibbs sampler}



% What is the IBP?
% Gibbs sampler to draw from prior
% Gibbs sampler to draw from posterior
% What is it used for?
% Where are the applications?
% Why would it be useful to include distance information?
% ddIBP?

\section{Methods} %~3-8 pages

%\bibliography{bibliography}
%\appendix
%\input appA.tex
\end{document}
